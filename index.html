<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Perceiver Multi-Scale Music Generation Demos</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>

  <header>
    <h1>Perceiver Multi-Scale Music Generation Demos</h1>
    <p>Explore the generated music samples from our experiments with the Perceiver AR model. Each demo showcases different configurations and settings.</p>
  </header>

  <section class="demo-container">
    <h2>Demos</h2>

    <!-- Example Demo -->
    <div class="demo-item">
      <h3>Demo 1: Baseline Model Output</h3>
      <audio controls>
        <source src="demos/demo1.mp3" type="audio/mp3">
        Your browser does not support the audio element.
      </audio>
      <p>Description: Generated using the baseline model on the Maestro dataset.</p>
    </div>

    <div class="demo-item">
      <h3>Demo 2: Improved Multi-Scale Attention</h3>
      <audio controls>
        <source src="demos/demo2.mp3" type="audio/mp3">
        Your browser does not support the audio element.
      </audio>
      <p>Description: Generated using multi-scale attention with two different scale masks.</p>
    </div>

    <div class="demo-item">
      <h3>Demo 3: Cascaded Cross Attention with Combined Datasets</h3>
      <audio controls>
        <source src="demos/demo3.mp3" type="audio/mp3">
        Your browser does not support the audio element.
      </audio>
      <p>Description: Fine-tuned on combined Maestro, GiantMIDI, and Atepp datasets.</p>
    </div>
    
  </section>

  <footer>
    <p>Learn more about this project on our <a href="https://github.com/perceiver-ms">GitHub repository</a>.</p>
  </footer>

</body>
</html>

